# -*- coding: utf-8 -*-
"""Untitled11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-OzbtD_m6_TR2_Izz68gfyWKfCxfjyJk
"""

!pip install scikit-learn pandas

!pip install openpyxl

from google.colab import files
uploaded = files.upload()

import pandas as pd
df = pd.read_excel('dataset.xlsx', engine='openpyxl')
df.head()

messages = df['Message']
labels = df['Category']

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(stop_words='english')
X = vectorizer.fit_transform(df['Message'])
y=df['Category']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score
from sklearn.preprocessing import LabelEncoder

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print(f"Confusion Matrix:\n{cm}")

# Convert string labels to numerical values using LabelEncoder
label_encoder = LabelEncoder()
y_test_encoded = label_encoder.fit_transform(y_test)
y_pred_encoded = label_encoder.transform(y_pred)

# ROC-AUC score
roc_auc = roc_auc_score(y_test_encoded, y_pred_encoded)
print(f"ROC-AUC Score: {roc_auc}")

import seaborn as sns
import matplotlib.pyplot as plt

# Visualize the Confusion Matrix
plt.figure(figsize=(5, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

from sklearn.metrics import roc_curve, auc

# Calculate false positive rate, true positive rate
fpr, tpr, thresholds = roc_curve(y_test_encoded, y_pred_encoded)

# Plot the ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='grey', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

from sklearn.model_selection import GridSearchCV

# Define the parameter grid
param_grid = {
    'C': [0.01, 0.1, 1, 10],  # Regularization strength
    'penalty': ['l1', 'l2'],   # Regularization type
    'solver': ['liblinear']    # Solver (liblinear for small datasets)
}

# Perform Grid Search with 5-fold cross-validation
grid_search = GridSearchCV(LogisticRegression(class_weight='balanced'), param_grid, scoring='roc_auc', cv=5)
grid_search.fit(X_train, y_train)

# Best parameters and best model
print(f"Best parameters: {grid_search.best_params_}")
best_model = grid_search.best_estimator_

# Evaluate the optimized model
y_pred_optimized = best_model.predict(X_test)
roc_auc_optimized = roc_auc_score(y_test_encoded, label_encoder.transform(y_pred_optimized))
print(f"Optimized ROC-AUC Score: {roc_auc_optimized}")

from sklearn.ensemble import RandomForestClassifier

# Train Random Forest
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Make predictions and evaluate
y_pred_rf = rf_model.predict(X_test)
roc_auc_rf = roc_auc_score(y_test_encoded, label_encoder.transform(y_pred_rf))
print(f"Random Forest ROC-AUC Score: {roc_auc_rf}")